{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.impute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b1a3e10bb3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.impute'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, RFECV, SequentialFeatureSelector\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import make_classification, load_wine, load_breast_cancer, load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(x, y, auto_scaled=True, title=None, clusters=None):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(x, y)\n",
    "    \n",
    "    if not auto_scaled:\n",
    "        plt.axis('square')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "def return_X_y(data, target_column):\n",
    "    return data.drop(target_column, axis=1), data[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('Melbourne_housing_FULL.csv')\n",
    "# prepare dataset for price regression\n",
    "housing_data = housing_data[~housing_data['Price'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data.isnull().mean() # housing_data.isnull().sum() to get absolute numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "housing_data_dropped = housing_data[housing_data.columns[housing_data.isnull().mean() < threshold]]\n",
    "housing_data_dropped = housing_data_dropped.dropna(axis=0, how='any') # params is optinal here (matching defaults)\n",
    "print(f'Original dataset shape (rows, cols): {housing_data.shape}')\n",
    "print(f'Dataset shape (rows, cols) after dropna: {housing_data_dropped.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const imputing\n",
    "housing_data_const = housing_data.fillna(value=0)\n",
    "\n",
    "# mean imputing\n",
    "housing_data_mean = housing_data.fillna(housing_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_sklearn = load_wine(as_frame=True)\n",
    "wine_data, wine_labels = wine_sklearn['data'], wine_sklearn['target']\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "wine_data_scaled = scaler.fit_transform(wine_data)\n",
    "wine_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "wine_data_pca = pca.fit_transform(wine_data)\n",
    "wine_data_scaled_pca = pca.fit_transform(wine_data_scaled)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18, 10))\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax1.scatter(wine_data_pca[wine_labels == l, 0], wine_data_pca[wine_labels == l, 1], \n",
    "                color=c, label=f'class {l}', alpha=0.5, marker=m)\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax2.scatter(wine_data_scaled_pca[wine_labels == l, 0], wine_data_scaled_pca[wine_labels == l, 1], \n",
    "                color=c, label=f'class {l}', alpha=0.5, marker=m)\n",
    "    \n",
    "ax1.set_title('Dataset after PCA')\n",
    "ax2.set_title('Standardized dataset after PCA')\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_xlabel('1st principal component')\n",
    "    ax.set_ylabel('2nd principal component')\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 5, 1\n",
    "lognorm_data = np.random.lognormal(mu, sigma, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.histplot(lognorm_data, stat='probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.histplot(np.log(lognorm_data), stat='probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.histplot(housing_data['Price'], stat='probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [['male', 'US', 'Safari'], ['female', 'Europe', 'Firefox'], ['male', 'Europe', 'Opera']]\n",
    "pd.DataFrame(X, columns=['gender', 'place', 'browser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "ordinal_encoded_X = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "ohe_encoded_X = encoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ohe_encoded_X, columns=encoder.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_sklearn = load_breast_cancer(as_frame=True)\n",
    "cancer_data, cancer_labels = cancer_sklearn['data'], cancer_sklearn['target']\n",
    "cancer_data_scaled = StandardScaler().fit_transform(cancer_data)\n",
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_generated, y_generated = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "                                                         n_redundant=2, n_repeated=0)\n",
    "X_generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(VarianceThreshold(0.9).fit_transform(X_generated).shape)\n",
    "print(VarianceThreshold(1).fit_transform(X_generated).shape)\n",
    "print(VarianceThreshold(1.1).fit_transform(X_generated).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_model = RandomForestClassifier(random_state=42)\n",
    "selector = SelectFromModel(selection_model).fit(cancer_data, cancer_labels)\n",
    "cancer_data_pruned = selector.transform(cancer_data)\n",
    "print(cancer_data.columns[selector.get_support()])\n",
    "print(f'Original shape: {cancer_data.shape}')\n",
    "print(f'Shape after selection: {cancer_data_pruned.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "pipe_baseline = make_pipeline(StandardScaler(), main_model)\n",
    "pipe_selection = make_pipeline(StandardScaler(), SelectFromModel(selection_model), main_model) # fix to select only once\n",
    "\n",
    "print('Result on original data: {:f}'.format(cross_val_score(pipe_baseline, cancer_data, cancer_labels, \n",
    "                      scoring='accuracy', cv=5).mean()))\n",
    "\n",
    "print('Result after selection {:f}'.format(cross_val_score(pipe_selection, cancer_data, cancer_labels, \n",
    "                      scoring='accuracy', cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_features_to_select = 1 \n",
    "rfecv = RFECV(estimator=main_model, step=1, cv=KFold(3), \n",
    "              scoring='accuracy', min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(cancer_data_scaled, cancer_labels)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SequentialFeatureSelector(main_model, scoring='accuracy', n_jobs=-1).fit(cancer_data_scaled, cancer_labels)\n",
    "cancer_data_scaled_pruned = selector.transform(cancer_data_scaled)\n",
    "\n",
    "print(cancer_data.columns[selector.get_support()])\n",
    "print(f'Original shape: {cancer_data.shape}')\n",
    "print(f'Shape after selection: {cancer_data_pruned.shape}\\n')\n",
    "\n",
    "print('Result on original data: {:f}'.format(cross_val_score(main_model, cancer_data_scaled, \n",
    "                                                           cancer_labels, scoring='accuracy', cv=5).mean()))\n",
    "\n",
    "print('Result after selection {:f}'.format(cross_val_score(main_model, cancer_data_scaled_pruned, \n",
    "                                                        cancer_labels, scoring='accuracy', cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ownStandardScaler(df):\n",
    "\n",
    "    own=df.iloc[:,:].round(decimals=12)\n",
    "    own_mean=df.iloc[:,:].mean().round(decimals=12)\n",
    "    sigma=(((((own-own_mean)**2).sum())/(df.shape[0]))**0.5).round(decimals=12)\n",
    "    own_scaled=((own-own_mean)/sigma).round(decimals=12)\n",
    "    print('\\n'\"own_scaled wine_data_scaled: \",np.allclose(own_scaled, wine_data_scaled))\n",
    "    return own_scaled\n",
    "\n",
    "ownStandardScaler(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_0 = np.random.randn(1000) * 10   \n",
    "feature_1 = np.concatenate([np.random.randn(500), np.random.randn(500) + 5])\n",
    "data = np.column_stack([feature_0, feature_1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(data[:, 0], data[:, 1], auto_scaled=True, title='Data (different axes units!)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(data[:, 0], data[:, 1], auto_scaled=False , title='Data (equal axes units!)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=pd.DataFrame(data).round(decimals=12)\n",
    "data_x_min=data_x.min()\n",
    "data_x_max=data_x.max()\n",
    "data_x_norm=(data_x-data_x_min)/(data_x_max-data_x_min)\n",
    "data_x_norm=np.asarray(data_x_norm)\n",
    "print(\"data_x_norm = \",'\\n',data_x_norm)\n",
    "plot_scatter(data_x_norm[:,0],data_x_norm[:,1], auto_scaled=False, title='Data (equal axes units!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=pd.DataFrame(data, columns=['feature_0','feature_1']).round(decimals=12)\n",
    "data_x_mean=data_x.iloc[:,:].mean().round(decimals=12)\n",
    "sigma=(((((data_x-data_x_mean)**2).sum())/(data_x.shape[0]))**0.5).round(decimals=12)\n",
    "data_x_scaled=((data_x-data_x_mean)/sigma).round(decimals=12)\n",
    "data_x_scaled=np.asarray(data_x_scaled)\n",
    "plot_scatter(data_x_scaled[:,0],data_x_scaled[:,1], auto_scaled=False, title='Data (equal axes units!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run algorithm (with k=2, k - number of clusters/classes) on unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_own(x,y,title=None):\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    clusters = Kmean.fit_predict(np.array([x, y]).T)\n",
    "    plt.title(title)\n",
    "    plt.scatter(x, y,c=clusters,cmap='bwr',marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "Kmean = KMeans(n_clusters=2)\n",
    "Kmean.fit(data)\n",
    "data_x=data[:,0]\n",
    "data_y=data[:,1]\n",
    "c_data=Kmean.cluster_centers_\n",
    "plot_scatter_own(data_x,data_y,title='k=2 on unscaled data')\n",
    "plt.scatter(c_data[0][0], c_data[0][1], c='y', marker='s')\n",
    "plt.scatter(c_data[1][0], c_data[1][1], c='b', marker='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run algorithm (with k=2) on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "Kmean = KMeans(n_clusters=2)\n",
    "Kmean.fit(data_x_scaled)\n",
    "data_x=data_x_scaled[:,0]\n",
    "data_y=data_x_scaled[:,1]\n",
    "\n",
    "c_data=Kmean.cluster_centers_\n",
    "plot_scatter_own(data_x,data_y,title='k=2 on scaled data')\n",
    "plt.scatter(c_data[0][0], c_data[0][1], c='y', marker='s')\n",
    "plt.scatter(c_data[1][0], c_data[1][1], c='g', marker='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "Kmean = KMeans(n_clusters=2)\n",
    "Kmean.fit(data_x_norm)\n",
    "data_x=data_x_norm[:,0]\n",
    "data_y=data_x_norm[:,1]\n",
    "\n",
    "c_data=Kmean.cluster_centers_\n",
    "plot_scatter_my(data_x,data_y,title='k=2 on minmax data')\n",
    "plt.scatter(c_data[0][0], c_data[0][1], c='g', marker='s')\n",
    "plt.scatter(c_data[1][0], c_data[1][1], c='y', marker='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train, wine_val, wine_labels_train, wine_labels_val = train_test_split(wine_data, wine_labels, \n",
    "                                                                            test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "pipe_baseline = make_pipeline(main_model)\n",
    "\n",
    "print('original data: {:f}'.format(cross_val_score(pipe_baseline, wine_val, wine_labels_val, \n",
    "                      scoring='accuracy', cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "pipe_selection = make_pipeline(StandardScaler(), SelectFromModel(selection_model), main_model) \n",
    "\n",
    "print('StandardScaler + FeatureSelection {:f}'.format(cross_val_score(pipe_selection, wine_val, wine_labels_val, \n",
    "                      scoring='accuracy', cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Результат при применении StandardScaler улучшился с 0,94 до 0,98\n",
    "Если добавить FeatureSelection то рехультат ухудшился до 0,96\n",
    "Вывод: FeatureSelection не всегда приводит к улучшению работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
